{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem Overview\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    " \n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal.\n",
    "\n",
    " \n",
    "\n",
    "To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    " \n",
    "\n",
    "In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Business Objective and the Data\n",
    "The dataset contains customer-level information for a span of four consecutive months - June, July, August and September. The months are encoded as 6, 7, 8 and 9, respectively. \n",
    "\n",
    "\n",
    "The business objective is to predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Customer Behaviour During Churn\n",
    "Customers usually do not decide to switch to another competitor instantly, but rather over a period of time (this is especially applicable to high-value customers). In churn prediction, we assume that there are three phases of customer lifecycle :\n",
    "\n",
    "The ‘good’ phase: In this phase, the customer is happy with the service and behaves as usual.\n",
    "\n",
    "The ‘action’ phase: The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a  competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘good’ months. Also, it is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)\n",
    "\n",
    "The ‘churn’ phase: In this phase, the customer is said to have churned. You define churn based on this phase. Also, it is important to note that at the time of prediction (i.e. the action months), this data is not available to you for prediction. Thus, after tagging churn as 1/0 based on this phase, you discard all data corresponding to this phase.\n",
    "\n",
    " \n",
    "\n",
    "In this case, since you are working over a four-month window, the first two months are the ‘good’ phase, the third month is the ‘action’ phase, while the fourth month is the ‘churn’ phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:13.902024Z",
     "start_time": "2021-04-24T14:49:13.896264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.metrics import  roc_auc_score,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:13.910524Z",
     "start_time": "2021-04-24T14:49:13.905716Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.672960Z",
     "start_time": "2021-04-24T14:49:13.913075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "cust = pd.read_csv(\"data/telecom_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.680179Z",
     "start_time": "2021-04-24T14:49:16.675694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 226)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.715765Z",
     "start_time": "2021-04-24T14:49:16.683228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6  ...  sachet_3g_9  fb_user_6  fb_user_7  \\\n",
       "0            9/30/2014  197.385  ...            0        1.0        1.0   \n",
       "1            9/30/2014   34.047  ...            0        NaN        1.0   \n",
       "2            9/30/2014  167.690  ...            0        NaN        NaN   \n",
       "3            9/30/2014  221.338  ...            0        NaN        NaN   \n",
       "4            9/30/2014  261.636  ...            0        0.0        NaN   \n",
       "\n",
       "   fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  \n",
       "0        1.0        NaN   968        30.4         0.0      101.20        3.58  \n",
       "1        1.0        NaN  1006         0.0         0.0        0.00        0.00  \n",
       "2        NaN        1.0  1103         0.0         0.0        4.17        0.00  \n",
       "3        NaN        NaN  2491         0.0         0.0        0.00        0.00  \n",
       "4        NaN        NaN  1526         0.0         0.0        0.00        0.00  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.727511Z",
     "start_time": "2021-04-24T14:49:16.718710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Smaller file to manually check on the first 10 records in the dataset\n",
    "cust.head(10).T.to_csv(\"sample_10_T.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.752295Z",
     "start_time": "2021-04-24T14:49:16.729659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Columns: 226 entries, mobile_number to sep_vbc_3g\n",
      "dtypes: float64(179), int64(35), object(12)\n",
      "memory usage: 172.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cust.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.760021Z",
     "start_time": "2021-04-24T14:49:16.754106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values in the dataframe and print them\n",
    "def print_missing_columns(input_df):\n",
    "    # Print missing percentage of only columns with missing values\n",
    "    missing_columns = input_df.columns[input_df.isnull().any()]\n",
    "    if not missing_columns.empty:\n",
    "        missing_count = input_df[missing_columns].isnull().sum()\n",
    "        missing_col_type = pd.Series([type(col) for col in input_df[missing_columns]],index = missing_columns) \n",
    "        unique_count = input_df[missing_columns].nunique()\n",
    "\n",
    "        missing_df = pd.concat({\n",
    "                        \"Missing\": missing_count, \n",
    "                        \"Missing %\": missing_count/len(input_df.index)*100,\n",
    "                        \"Type\": missing_col_type,\n",
    "                        \"Unique Count\": unique_count\n",
    "                       } , \n",
    "                       axis = 1).sort_values(by = 'Missing', ascending = False)\n",
    "\n",
    "        display(missing_df)\n",
    "    else:\n",
    "        display(\"NO MISSING VALUES IN THE DATAFRAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <TODO> Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:49:16.774364Z",
     "start_time": "2021-04-24T14:49:16.762510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99999 entries, 0 to 99998\n",
      "Columns: 226 entries, mobile_number to sep_vbc_3g\n",
      "dtypes: float64(179), int64(35), object(12)\n",
      "memory usage: 172.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cust.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date columns are present as objects. Convert to datetime type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:26.258598Z",
     "start_time": "2021-04-24T14:49:16.778597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change data type of date columns to datetime\n",
    "date_cols = [col for col in cust.columns if re.match('^date|^last_date', col)]\n",
    "cust[date_cols] = cust[date_cols].apply(pd.to_datetime,errors='coerce') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.018728Z",
     "start_time": "2021-04-24T14:50:26.262403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing</th>\n",
       "      <th>Missing %</th>\n",
       "      <th>Type</th>\n",
       "      <th>Unique Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_3g_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>7418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_rech_amt_data_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_3g_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_6</th>\n",
       "      <td>74846</td>\n",
       "      <td>74.846748</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_3g_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_3g_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>7246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_rech_amt_data_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_7</th>\n",
       "      <td>74428</td>\n",
       "      <td>74.428744</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_data_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_3g_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>av_rech_amt_data_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_3g_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>8063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_2g_9</th>\n",
       "      <td>74077</td>\n",
       "      <td>74.077741</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2m_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>20018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2f_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2c_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>5230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>4396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2t_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>13511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2m_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>21918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>31023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>28390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2t_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>6481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2m_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>9464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2f_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>3209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_t2o_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_ic_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>11889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_ic_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ic_others_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>24336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2t_mou_7</th>\n",
       "      <td>3859</td>\n",
       "      <td>3.859039</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>13411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "      <td>3622</td>\n",
       "      <td>3.622036</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <td>1767</td>\n",
       "      <td>1.767018</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <td>1659</td>\n",
       "      <td>1.659017</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <td>1607</td>\n",
       "      <td>1.607016</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <td>1100</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <td>1018</td>\n",
       "      <td>1.018010</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <td>1018</td>\n",
       "      <td>1.018010</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <td>1018</td>\n",
       "      <td>1.018010</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <td>601</td>\n",
       "      <td>0.601006</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Missing  Missing %           Type  Unique Count\n",
       "count_rech_2g_6             74846  74.846748  <class 'str'>            31\n",
       "max_rech_data_6             74846  74.846748  <class 'str'>            48\n",
       "arpu_3g_6                   74846  74.846748  <class 'str'>          7418\n",
       "av_rech_amt_data_6          74846  74.846748  <class 'str'>           887\n",
       "count_rech_3g_6             74846  74.846748  <class 'str'>            25\n",
       "night_pck_user_6            74846  74.846748  <class 'str'>             2\n",
       "arpu_2g_6                   74846  74.846748  <class 'str'>          6990\n",
       "fb_user_6                   74846  74.846748  <class 'str'>             2\n",
       "total_rech_data_6           74846  74.846748  <class 'str'>            37\n",
       "date_of_last_rech_data_6    74846  74.846748  <class 'str'>            30\n",
       "count_rech_3g_7             74428  74.428744  <class 'str'>            28\n",
       "arpu_3g_7                   74428  74.428744  <class 'str'>          7246\n",
       "av_rech_amt_data_7          74428  74.428744  <class 'str'>           961\n",
       "fb_user_7                   74428  74.428744  <class 'str'>             2\n",
       "total_rech_data_7           74428  74.428744  <class 'str'>            42\n",
       "count_rech_2g_7             74428  74.428744  <class 'str'>            36\n",
       "arpu_2g_7                   74428  74.428744  <class 'str'>          6586\n",
       "night_pck_user_7            74428  74.428744  <class 'str'>             2\n",
       "max_rech_data_7             74428  74.428744  <class 'str'>            48\n",
       "date_of_last_rech_data_7    74428  74.428744  <class 'str'>            31\n",
       "date_of_last_rech_data_9    74077  74.077741  <class 'str'>            30\n",
       "count_rech_2g_9             74077  74.077741  <class 'str'>            32\n",
       "total_rech_data_9           74077  74.077741  <class 'str'>            37\n",
       "count_rech_3g_9             74077  74.077741  <class 'str'>            27\n",
       "max_rech_data_9             74077  74.077741  <class 'str'>            50\n",
       "av_rech_amt_data_9          74077  74.077741  <class 'str'>           945\n",
       "arpu_3g_9                   74077  74.077741  <class 'str'>          8063\n",
       "fb_user_9                   74077  74.077741  <class 'str'>             2\n",
       "night_pck_user_9            74077  74.077741  <class 'str'>             2\n",
       "arpu_2g_9                   74077  74.077741  <class 'str'>          6795\n",
       "...                           ...        ...            ...           ...\n",
       "std_og_t2m_mou_7             3859   3.859039  <class 'str'>         20018\n",
       "std_og_t2f_mou_7             3859   3.859039  <class 'str'>          2391\n",
       "std_og_t2c_mou_7             3859   3.859039  <class 'str'>             1\n",
       "roam_ic_mou_7                3859   3.859039  <class 'str'>          5230\n",
       "isd_og_mou_7                 3859   3.859039  <class 'str'>          1380\n",
       "spl_og_mou_7                 3859   3.859039  <class 'str'>          4396\n",
       "og_others_7                  3859   3.859039  <class 'str'>           187\n",
       "loc_ic_t2t_mou_7             3859   3.859039  <class 'str'>         13511\n",
       "loc_ic_t2m_mou_7             3859   3.859039  <class 'str'>         21918\n",
       "offnet_mou_7                 3859   3.859039  <class 'str'>         31023\n",
       "loc_ic_mou_7                 3859   3.859039  <class 'str'>         28390\n",
       "std_ic_t2t_mou_7             3859   3.859039  <class 'str'>          6481\n",
       "std_ic_t2m_mou_7             3859   3.859039  <class 'str'>          9464\n",
       "std_ic_t2f_mou_7             3859   3.859039  <class 'str'>          3209\n",
       "std_ic_t2o_mou_7             3859   3.859039  <class 'str'>             1\n",
       "std_ic_mou_7                 3859   3.859039  <class 'str'>         11889\n",
       "spl_ic_mou_7                 3859   3.859039  <class 'str'>           107\n",
       "isd_ic_mou_7                 3859   3.859039  <class 'str'>          5789\n",
       "ic_others_7                  3859   3.859039  <class 'str'>          2002\n",
       "onnet_mou_7                  3859   3.859039  <class 'str'>         24336\n",
       "loc_og_t2t_mou_7             3859   3.859039  <class 'str'>         13411\n",
       "date_of_last_rech_8          3622   3.622036  <class 'str'>            31\n",
       "date_of_last_rech_7          1767   1.767018  <class 'str'>            31\n",
       "last_date_of_month_9         1659   1.659017  <class 'str'>             1\n",
       "date_of_last_rech_6          1607   1.607016  <class 'str'>            30\n",
       "last_date_of_month_8         1100   1.100011  <class 'str'>             1\n",
       "std_og_t2o_mou               1018   1.018010  <class 'str'>             1\n",
       "loc_ic_t2o_mou               1018   1.018010  <class 'str'>             1\n",
       "loc_og_t2o_mou               1018   1.018010  <class 'str'>             1\n",
       "last_date_of_month_7          601   0.601006  <class 'str'>             1\n",
       "\n",
       "[166 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_missing_columns(cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing with 0\n",
    "- Missing 'incoming' & 'outgoing' call related columns can be set to 0 assuming there were no calls received/made for that column type\n",
    "- Recharge related columns can be set to 0 assuming empty cells indicate no recharge was done in that month\n",
    "- Minutes of Usage (MoU) and average revenue per user (arpu) columns are also handled similarly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.025010Z",
     "start_time": "2021-04-24T14:50:31.020824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mobile_number', 'circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou',\n",
       "       'loc_ic_t2o_mou', 'last_date_of_month_6', 'last_date_of_month_7',\n",
       "       'last_date_of_month_8', 'last_date_of_month_9', 'arpu_6',\n",
       "       ...\n",
       "       'sachet_3g_9', 'fb_user_6', 'fb_user_7', 'fb_user_8', 'fb_user_9',\n",
       "       'aon', 'aug_vbc_3g', 'jul_vbc_3g', 'jun_vbc_3g', 'sep_vbc_3g'],\n",
       "      dtype='object', length=226)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.240621Z",
     "start_time": "2021-04-24T14:50:31.027099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced missing values with 0 for 57 incoming columns:['loc_ic_t2o_mou', 'roam_ic_mou_6', 'roam_ic_mou_7', 'roam_ic_mou_8', 'roam_ic_mou_9', 'loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_7', 'loc_ic_t2t_mou_8', 'loc_ic_t2t_mou_9', 'loc_ic_t2m_mou_6', 'loc_ic_t2m_mou_7', 'loc_ic_t2m_mou_8', 'loc_ic_t2m_mou_9', 'loc_ic_t2f_mou_6', 'loc_ic_t2f_mou_7', 'loc_ic_t2f_mou_8', 'loc_ic_t2f_mou_9', 'loc_ic_mou_6', 'loc_ic_mou_7', 'loc_ic_mou_8', 'loc_ic_mou_9', 'std_ic_t2t_mou_6', 'std_ic_t2t_mou_7', 'std_ic_t2t_mou_8', 'std_ic_t2t_mou_9', 'std_ic_t2m_mou_6', 'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8', 'std_ic_t2m_mou_9', 'std_ic_t2f_mou_6', 'std_ic_t2f_mou_7', 'std_ic_t2f_mou_8', 'std_ic_t2f_mou_9', 'std_ic_t2o_mou_6', 'std_ic_t2o_mou_7', 'std_ic_t2o_mou_8', 'std_ic_t2o_mou_9', 'std_ic_mou_6', 'std_ic_mou_7', 'std_ic_mou_8', 'std_ic_mou_9', 'total_ic_mou_6', 'total_ic_mou_7', 'total_ic_mou_8', 'total_ic_mou_9', 'spl_ic_mou_6', 'spl_ic_mou_7', 'spl_ic_mou_8', 'spl_ic_mou_9', 'isd_ic_mou_6', 'isd_ic_mou_7', 'isd_ic_mou_8', 'isd_ic_mou_9', 'ic_others_6', 'ic_others_7', 'ic_others_8', 'ic_others_9']\n",
      "\n",
      "Replaced missing values with 0 for 62 outgoing columns:['loc_og_t2o_mou', 'std_og_t2o_mou', 'roam_og_mou_6', 'roam_og_mou_7', 'roam_og_mou_8', 'roam_og_mou_9', 'loc_og_t2t_mou_6', 'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8', 'loc_og_t2t_mou_9', 'loc_og_t2m_mou_6', 'loc_og_t2m_mou_7', 'loc_og_t2m_mou_8', 'loc_og_t2m_mou_9', 'loc_og_t2f_mou_6', 'loc_og_t2f_mou_7', 'loc_og_t2f_mou_8', 'loc_og_t2f_mou_9', 'loc_og_t2c_mou_6', 'loc_og_t2c_mou_7', 'loc_og_t2c_mou_8', 'loc_og_t2c_mou_9', 'loc_og_mou_6', 'loc_og_mou_7', 'loc_og_mou_8', 'loc_og_mou_9', 'std_og_t2t_mou_6', 'std_og_t2t_mou_7', 'std_og_t2t_mou_8', 'std_og_t2t_mou_9', 'std_og_t2m_mou_6', 'std_og_t2m_mou_7', 'std_og_t2m_mou_8', 'std_og_t2m_mou_9', 'std_og_t2f_mou_6', 'std_og_t2f_mou_7', 'std_og_t2f_mou_8', 'std_og_t2f_mou_9', 'std_og_t2c_mou_6', 'std_og_t2c_mou_7', 'std_og_t2c_mou_8', 'std_og_t2c_mou_9', 'std_og_mou_6', 'std_og_mou_7', 'std_og_mou_8', 'std_og_mou_9', 'isd_og_mou_6', 'isd_og_mou_7', 'isd_og_mou_8', 'isd_og_mou_9', 'spl_og_mou_6', 'spl_og_mou_7', 'spl_og_mou_8', 'spl_og_mou_9', 'og_others_6', 'og_others_7', 'og_others_8', 'og_others_9', 'total_og_mou_6', 'total_og_mou_7', 'total_og_mou_8', 'total_og_mou_9']\n"
     ]
    }
   ],
   "source": [
    "# Incoming calls column:\n",
    "# All columns with incoming call information have the string \"ic_\" in the column name\n",
    "# Fill the missing values in these columns with 0\n",
    "incoming_cols = [col for col in cust.columns if 'ic_' in col]\n",
    "cust[incoming_cols] = cust[incoming_cols].fillna(0)\n",
    "print(f'Replaced missing values with 0 for {len(incoming_cols)} incoming columns:{incoming_cols}')\n",
    "\n",
    "# Outgoing calls column:\n",
    "# All columns with outgoing call information have the string \"og_\" in the column name\n",
    "# Fill the missing values in these columns with 0\n",
    "outcoming_cols = [col for col in cust.columns if 'og_' in col]\n",
    "cust[outcoming_cols] = cust[outcoming_cols].fillna(0)\n",
    "print(f'\\nReplaced missing values with 0 for {len(outcoming_cols)} outgoing columns:{outcoming_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.312723Z",
     "start_time": "2021-04-24T14:50:31.242906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced missing values with 0 for 32 recharge columns :['total_rech_num_6', 'total_rech_num_7', 'total_rech_num_8', 'total_rech_num_9', 'total_rech_amt_6', 'total_rech_amt_7', 'total_rech_amt_8', 'total_rech_amt_9', 'max_rech_amt_6', 'max_rech_amt_7', 'max_rech_amt_8', 'max_rech_amt_9', 'total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9', 'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9', 'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_2g_9', 'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9']\n"
     ]
    }
   ],
   "source": [
    "# Recharge related columns\n",
    "rech_cols = [col for col in cust.columns if re.match('^count_rech_|^max_rech_|^total_rech_|^av_rech_', col)]\n",
    "cust[rech_cols] = cust[rech_cols].fillna(0)\n",
    "print(f'Replaced missing values with 0 for {len(rech_cols)} recharge columns :{rech_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.331948Z",
     "start_time": "2021-04-24T14:50:31.315888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced missing values with 0 for 8 OFFNET/ONNET MOU columns :['onnet_mou_6', 'onnet_mou_7', 'onnet_mou_8', 'onnet_mou_9', 'offnet_mou_6', 'offnet_mou_7', 'offnet_mou_8', 'offnet_mou_9']\n"
     ]
    }
   ],
   "source": [
    "# OFFNET/ONNET MOU related columns\n",
    "mou_cols = [col for col in cust.columns if re.match('^onnet_mou|^offnet_mou', col)]\n",
    "cust[mou_cols] = cust[mou_cols].fillna(0)\n",
    "print(f'Replaced missing values with 0 for {len(mou_cols)} OFFNET/ONNET MOU columns :{mou_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.358669Z",
     "start_time": "2021-04-24T14:50:31.334555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced missing values with 0 for 12 arpu columns :['arpu_6', 'arpu_7', 'arpu_8', 'arpu_9', 'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8', 'arpu_3g_9', 'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8', 'arpu_2g_9']\n"
     ]
    }
   ],
   "source": [
    "# arpu related columns\n",
    "arpu_cols = [col for col in cust.columns if re.match('^arpu', col)]\n",
    "cust[arpu_cols] = cust[arpu_cols].fillna(0)\n",
    "print(f'Replaced missing values with 0 for {len(arpu_cols)} arpu columns :{arpu_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle date columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last recharges made for talktime and data for each month is provided in the input data<br>\n",
    "- With this information, we will create a new derived column which has the number of days since the last recharge <br>\n",
    "- Combine the columns for the good phase & action phase (months 6, 7 & 8) and get the latest date when a recharge was made <br>\n",
    "- At the beginning of 9th month, get the number of days since the last recharge <br>\n",
    "<br>\n",
    "Hypothesis - if the customer has done a recharge recently, they are less likely to churn.  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.366032Z",
     "start_time": "2021-04-24T14:50:31.361225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before handling date columns:(99999, 226)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape before handling date columns:{cust.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.377501Z",
     "start_time": "2021-04-24T14:50:31.368624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last_date_of_month_6',\n",
       " 'last_date_of_month_7',\n",
       " 'last_date_of_month_8',\n",
       " 'last_date_of_month_9',\n",
       " 'date_of_last_rech_6',\n",
       " 'date_of_last_rech_7',\n",
       " 'date_of_last_rech_8',\n",
       " 'date_of_last_rech_9',\n",
       " 'date_of_last_rech_data_6',\n",
       " 'date_of_last_rech_data_7',\n",
       " 'date_of_last_rech_data_8',\n",
       " 'date_of_last_rech_data_9']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:31.404305Z",
     "start_time": "2021-04-24T14:50:31.382752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_last_rech_6</th>\n",
       "      <th>date_of_last_rech_7</th>\n",
       "      <th>date_of_last_rech_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>2014-07-20</td>\n",
       "      <td>2014-08-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>2014-08-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2014-06-13</td>\n",
       "      <td>2014-07-26</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>2014-07-19</td>\n",
       "      <td>2014-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2014-06-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_of_last_rech_6 date_of_last_rech_7 date_of_last_rech_8\n",
       "99994          2014-06-03          2014-07-20          2014-08-26\n",
       "99995          2014-06-17          2014-07-17          2014-08-24\n",
       "99996          2014-06-13          2014-07-26                 NaT\n",
       "99997          2014-06-17          2014-07-19          2014-08-20\n",
       "99998          2014-06-16                 NaT                 NaT"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust[['date_of_last_rech_6','date_of_last_rech_7','date_of_last_rech_8']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.307780Z",
     "start_time": "2021-04-24T14:50:31.407533Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-c1d1df44e6d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the last recharge date in the good phase & action phase (gaphase) together (Months 6,7,8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlast_rech_date_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^date_of_last_.*[_6|_7|_8]$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_rech_date_gaphase'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_rech_date_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6485\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-155-c1d1df44e6d6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the last recharge date in the good phase & action phase (gaphase) together (Months 6,7,8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlast_rech_date_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^date_of_last_.*[_6|_7|_8]$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_rech_date_gaphase'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_rech_date_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10954\u001b[0m                                       skipna=skipna)\n\u001b[1;32m  10955\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m> 10956\u001b[0;31m                             numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m  10957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10958\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   3620\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3621\u001b[0m             \u001b[0;31m# use DatetimeIndex implementation to handle skipna correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3622\u001b[0;31m             \u001b[0mdelegate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3624\u001b[0m         \u001b[0;31m# dispatch to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, freq, start, end, periods, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name, verify_integrity)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myearfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             int_as_wall_time=True)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         subarr = cls._simple_new(dtarr, name=name,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_from_sequence\u001b[0;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous, int_as_wall_time)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myearfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             ambiguous=ambiguous, int_as_wall_time=int_as_wall_time)\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         freq, freq_infer = dtl.validate_inferred_freq(freq, inferred_freq,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36msequence_to_dt64ns\u001b[0;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous, int_as_wall_time)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m     \u001b[0;31m# By this point we are assured to have either a numpy array or Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mmaybe_convert_dtype\u001b[0;34m(data, copy)\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_NS_DTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1925\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m         \u001b[0;31m# Note: without explicitly raising here, PeriodIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;31m#  test_setops.test_join_does_not_recur fails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_period_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPeriodDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPeriodDtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         if isinstance(dtype, (ABCSeries, ABCIndexClass,\n\u001b[0;32m--> 101\u001b[0;31m                               ABCDataFrame, np.dtype)):\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_typ'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__instancecheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find the last recharge date in the good phase & action phase (gaphase) together (Months 6,7,8)\n",
    "last_rech_date_cols = [col for col in cust.columns if re.match('^date_of_last_.*[_6|_7|_8]$', col)]\n",
    "cust['last_rech_date_gaphase'] = cust[last_rech_date_cols].apply(lambda x: x.max(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.361775Z",
     "start_time": "2021-04-24T14:49:14.026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "cust['last_rech_date_gaphase'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.363031Z",
     "start_time": "2021-04-24T14:49:14.032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Missing values in this new column implies no recharge has happend in the 3 months.\n",
    "# Fill missing value with last date of previous month before the start of good phase\n",
    "last_rech_date_missing = datetime.datetime(2014, 5, 31)\n",
    "cust['last_rech_date_gaphase']=cust['last_rech_date_gaphase'].fillna(last_rech_date_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.364232Z",
     "start_time": "2021-04-24T14:49:14.037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create column for number of  days since last recharge\n",
    "last_date_action_phase = datetime.datetime(2014, 8, 31)\n",
    "cust['last_rech_num_days'] = (last_date_action_phase - cust['last_rech_date_gaphase']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.365356Z",
     "start_time": "2021-04-24T14:49:14.043Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['last_rech_date_gaphase','last_rech_num_days']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.366711Z",
     "start_time": "2021-04-24T14:49:14.049Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop date columns after creating the days columns\n",
    "print(f'Shape before dropping date columns:{cust.shape}')\n",
    "cust.drop(date_cols,inplace=True,axis=1)\n",
    "cust.drop('last_rech_date_gaphase',inplace=True,axis=1)\n",
    "print(f'Shape after dropping date columns:{cust.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.368030Z",
     "start_time": "2021-04-24T14:49:14.055Z"
    }
   },
   "outputs": [],
   "source": [
    "print_missing_columns(cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining missing values are filled using the IterativeImputer in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.369190Z",
     "start_time": "2021-04-24T14:49:14.063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use iterative imputer to fill the rest of the missing colums (fb_user_* and night_pck_user_* columns)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "iter_imputer = IterativeImputer()\n",
    "\n",
    "fb_night_cols = [col for col in cust.columns if re.match('^fb_user_|^night_pck_user_', col)]\n",
    "\n",
    "cust[fb_night_cols] = iter_imputer.fit_transform(cust[fb_night_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.370539Z",
     "start_time": "2021-04-24T14:49:14.069Z"
    }
   },
   "outputs": [],
   "source": [
    "print_missing_columns(cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check & Treat for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.372168Z",
     "start_time": "2021-04-24T14:49:14.078Z"
    }
   },
   "outputs": [],
   "source": [
    "[col for col in cust_orig.columns if re.match('.*arpu.*', col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.373332Z",
     "start_time": "2021-04-24T14:49:14.084Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['arpu_6','arpu_7','arpu_8']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.374512Z",
     "start_time": "2021-04-24T14:49:14.089Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust[['onnet_mou_6','onnet_mou_7','onnet_mou_8','offnet_mou_6','offnet_mou_7','offnet_mou_8']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.375575Z",
     "start_time": "2021-04-24T14:49:14.096Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['onnet_mou_6','onnet_mou_7','onnet_mou_8','offnet_mou_6','offnet_mou_7','offnet_mou_8']].describe(percentiles = [0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.376734Z",
     "start_time": "2021-04-24T14:49:14.103Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cust.describe(percentiles = [0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all the columns have outliers in the last one percentile. <br>\n",
    "Let us cap all the numeric columns to 99% percentile value to remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.377593Z",
     "start_time": "2021-04-24T14:49:14.110Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['arpu_6','arpu_7','arpu_8']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.378897Z",
     "start_time": "2021-04-24T14:49:14.116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop outliers with a cap of 99% \n",
    "columns_outliers = ['arpu_6','arpu_7','arpu_8']\n",
    "\n",
    "cap_arpu_6 = cust['arpu_6'].quantile(.99)\n",
    "cap_arpu_7 = cust['arpu_7'].quantile(.99)\n",
    "cap_arpu_8 = cust['arpu_8'].quantile(.99)\n",
    "cust =  cust[(cust['arpu_6'] <= cap_arpu_6) & (cust['arpu_7'] <= cap_arpu_7) & (cust['arpu_8'] <= cap_arpu_8)] \n",
    "\n",
    "# for col in columns_outliers:\n",
    "#     #floor = prices[col].quantile(.01)\n",
    "#     cap = cust[col].quantile(.99)\n",
    "#     cust =  cust[(cust[col] <= cap)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.380011Z",
     "start_time": "2021-04-24T14:49:14.122Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['arpu_6','arpu_7','arpu_8']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.381048Z",
     "start_time": "2021-04-24T14:49:14.128Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.382000Z",
     "start_time": "2021-04-24T14:49:14.135Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.describe(percentiles = [0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.383129Z",
     "start_time": "2021-04-24T14:49:14.140Z"
    }
   },
   "outputs": [],
   "source": [
    "6000/60/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove columns with only one unique value. \n",
    "Columns with only one unique value will not add much value to the analysis and can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.384165Z",
     "start_time": "2021-04-24T14:49:14.147Z"
    }
   },
   "outputs": [],
   "source": [
    "cust = cust[[col for col in cust.columns if cust[col].nunique() > 1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop ID column - mobile_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.385205Z",
     "start_time": "2021-04-24T14:49:14.157Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.drop(['mobile_number'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.386184Z",
     "start_time": "2021-04-24T14:49:14.162Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target variable from 9th Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the target variable based on the below rule:\n",
    " \n",
    "Tag the churned customers (churn=1, else 0) based on the fourth month as follows: Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes you need to use to tag churners are:\n",
    "\n",
    "total_ic_mou_9,\n",
    "total_og_mou_9,\n",
    "vol_2g_mb_9,\n",
    "vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.387261Z",
     "start_time": "2021-04-24T14:49:14.172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create churn flag based on the 9th month variables. \n",
    "cust['churn'] = (cust['total_ic_mou_9']+cust['total_og_mou_9']+cust['vol_2g_mb_9']+cust['vol_3g_mb_9']) == 0\n",
    "cust['churn']=cust['churn'].map({True:1,False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.388376Z",
     "start_time": "2021-04-24T14:49:14.178Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove 9th month variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.389560Z",
     "start_time": "2021-04-24T14:49:14.185Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the columns with the suffix _9, they should not be used while training the model.\n",
    "\n",
    "print(f'Shape before dropping 9th month columns:{cust.shape}')\n",
    "month_9_cols = [col for col in cust.columns if re.search('_9$', col)]\n",
    "cust.drop(month_9_cols,inplace=True,axis=1)\n",
    "print(f'Shape after dropping 9th month columns:{cust.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the 9th month variables after creating the target variables. Would otherwise lead to data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify High Value Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to predict churn only for the high-value customers. <br>\n",
    "Define high-value customers as follows: Those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months (the good phase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find average of M6,M7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.390621Z",
     "start_time": "2021-04-24T14:49:14.197Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.391634Z",
     "start_time": "2021-04-24T14:49:14.203Z"
    }
   },
   "outputs": [],
   "source": [
    "m6_cols = [col for col in cust.columns if re.search('.*rech.*_6$' , col)]\n",
    "cust[m6_cols].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.392622Z",
     "start_time": "2021-04-24T14:49:14.208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check if total recharge data column is same as sum of no. of recharges in 2G & 3G\n",
    "print(cust[cust['total_rech_data_6'] != (cust['count_rech_2g_6']+cust['count_rech_3g_6'])].empty)\n",
    "print(cust[cust['total_rech_data_7'] != (cust['count_rech_2g_7']+cust['count_rech_3g_7'])].empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T03:58:38.573128Z",
     "start_time": "2021-04-19T03:58:38.556861Z"
    }
   },
   "source": [
    "Assumption: total_rech_amt_* column is only for the talktime recharge and not for data recharge <br>\n",
    "This information is not clear in the data dictionary and requires domain knowledge. <br>\n",
    "We can compute the total rech amount for a month as sum of (talktime recharge + data recharge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.393718Z",
     "start_time": "2021-04-24T14:49:14.215Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['avg_rech_amt_6_7'] = ((cust['total_rech_amt_6'] + cust['total_rech_data_6']*cust['av_rech_amt_data_6']) +\n",
    "                            (cust['total_rech_amt_7'] + cust['total_rech_data_7']*cust['av_rech_amt_data_7']))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.394889Z",
     "start_time": "2021-04-24T14:49:14.220Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['total_rech_amt_6','total_rech_data_6','av_rech_amt_data_6','total_rech_data_7','av_rech_amt_data_7','total_rech_amt_7','avg_rech_amt_6_7']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually computing the average recharge amount looks to be correct. <br>\n",
    "We can now identify the value at the 70th percentile to identify the High Value Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify value at 70th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.395804Z",
     "start_time": "2021-04-24T14:49:14.228Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[['avg_rech_amt_6_7']].describe(percentiles=[0.1,0.3,0.5,0.7,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.396839Z",
     "start_time": "2021-04-24T14:49:14.233Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_70 = cust[['avg_rech_amt_6_7']].quantile(0.7)[0]\n",
    "print(f'Value at 70th percentile:{avg_70}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flag high value customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.397907Z",
     "start_time": "2021-04-24T14:49:14.239Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['is_hvc'] = cust['avg_rech_amt_6_7'].apply(lambda x: int(x>= avg_70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.398969Z",
     "start_time": "2021-04-24T14:49:14.246Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['is_hvc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:13:31.014818Z",
     "start_time": "2021-04-23T05:13:31.011570Z"
    }
   },
   "source": [
    "## Filter data for high value customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.400007Z",
     "start_time": "2021-04-24T14:49:14.252Z"
    }
   },
   "outputs": [],
   "source": [
    "cust_orig = cust.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.400978Z",
     "start_time": "2021-04-24T14:49:14.258Z"
    }
   },
   "outputs": [],
   "source": [
    "cust = cust[cust['is_hvc'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.401904Z",
     "start_time": "2021-04-24T14:49:14.264Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.402927Z",
     "start_time": "2021-04-24T14:49:14.269Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the columns created\n",
    "cust.drop(['is_hvc'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.404027Z",
     "start_time": "2021-04-24T14:49:14.276Z"
    }
   },
   "outputs": [],
   "source": [
    "m8_toc_cols = ['loc_og_t2c_mou_8']\n",
    "aon_cols = ['aon']\n",
    "mou_cols = [col for col in cust.columns if re.search('^total_.*mou.*' , col)]\n",
    "\n",
    "cols_to_analyse = m8_toc_cols+aon_cols+mou_cols\n",
    "cols_to_analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.405382Z",
     "start_time": "2021-04-24T14:49:14.282Z"
    }
   },
   "outputs": [],
   "source": [
    "cust[cols_to_analyse].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.406469Z",
     "start_time": "2021-04-24T14:49:14.288Z"
    }
   },
   "outputs": [],
   "source": [
    "DEPENDENT_VARIABLE = 'churn'\n",
    "CONTINUOUS_VAR_TO_ANALYSE = cols_to_analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.407322Z",
     "start_time": "2021-04-24T14:49:14.299Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['churn'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.408874Z",
     "start_time": "2021-04-24T14:49:14.305Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,8))\n",
    "fig.suptitle('Defaulters Distribution', fontsize=24)\n",
    "ax = cust[DEPENDENT_VARIABLE].value_counts().plot.bar()\n",
    "for p in ax.patches: \n",
    "    ax.annotate(\"%0.0f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', fontsize=11,  xytext=(0, 10), textcoords='offset points')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Features - Univariate & Segmented Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.410893Z",
     "start_time": "2021-04-24T14:49:14.313Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# For each continuous variable, plot\n",
    "# a. Distribution plot for each continuous variable - Univariate Analysis\n",
    "# b. Distribution plot against the target variable - Segmented Univariate Analysis\n",
    "for col in CONTINUOUS_VAR_TO_ANALYSE:\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 8))\n",
    "    fig.suptitle(col, fontsize=18)\n",
    "    sns.distplot(cust[col], kde=False, ax=ax[0])\n",
    "    for i in sorted(cust[DEPENDENT_VARIABLE].unique()):\n",
    "        sns.distplot(cust[cust[DEPENDENT_VARIABLE] == i][col], kde=False, ax=ax[1], label=f'{DEPENDENT_VARIABLE} = {i}')\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map/correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.412667Z",
     "start_time": "2021-04-24T14:49:14.321Z"
    }
   },
   "outputs": [],
   "source": [
    "df = cust[CONTINUOUS_VAR_TO_ANALYSE + ['churn']]\n",
    "corr = df.corr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.414520Z",
     "start_time": "2021-04-24T14:49:14.328Z"
    }
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20, 15))\n",
    "\n",
    "ax = plt.matshow(corr, fignum=f.number,cmap='RdYlGn')\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=14)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "#ax.set_ylim([0,2])\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.416656Z",
     "start_time": "2021-04-24T14:49:14.335Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.419125Z",
     "start_time": "2021-04-24T14:49:14.342Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<TODO> Insights:\n",
    "    High correlation between 2 consecutive months (M6 & M7, M7 & M8).<br>\n",
    "    Good correlation between alternate months (M6 & M8)<br>\n",
    "--     Churn is negatively correlated to the calls made to the customer care (t2c). More calls to customer care implies more chances of churning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Derive new feature on average usage in good & action phase \n",
    "- Derive new feature on usage during action phase vs good phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.421391Z",
     "start_time": "2021-04-24T14:49:14.351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Method to create the derived features for the given column pattern\n",
    "# 1. Creates two derived features - average of 3 months, good vs action phase\n",
    "# 2. Drops the features from which the new columns were created to remove multicollinearity\n",
    "def create_derived_avg_variables(pattern,col_prefix):\n",
    "   # Create columns for the good phase & action phase\n",
    "    gphase_cols = [col for col in cust.columns if re.match(f'{pattern}[_6|_7]$', col)]\n",
    "    aphase_cols = [col for col in cust.columns if re.match(f'{pattern}[_8]$', col)]\n",
    "\n",
    "    # Get average for 3 months\n",
    "    cust[f'{col_prefix}_avg'] = round((cust[gphase_cols].sum(axis=1)+cust[aphase_cols].sum(axis=1))/3,2)\n",
    "\n",
    "    # Get the differece between action phase & average value in good phase\n",
    "    # Hypothesis: If the values are in negative, it implies that the variable has reduced in the action phase as compared to an average in the good phase - more likely to churn\n",
    "    cust[f'{col_prefix}_gaphase_avg'] = round(cust[aphase_cols].sum(axis=1) - (cust[gphase_cols].sum(axis=1))/2,2) \n",
    "    \n",
    "    # Verify Values\n",
    "    print('Sample data for cross-verification:')\n",
    "    display(cust[gphase_cols + aphase_cols +[f'{col_prefix}_avg',f'{col_prefix}_gaphase_avg']].tail())\n",
    "    \n",
    "    # Drop monthly arpu related columns after creating the derived variables\n",
    "    cust.drop(gphase_cols, axis=1, inplace=True)\n",
    "    cust.drop(aphase_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.423552Z",
     "start_time": "2021-04-24T14:49:14.357Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive based on ARPU (Average Revenue Per User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.425217Z",
     "start_time": "2021-04-24T14:49:14.367Z"
    }
   },
   "outputs": [],
   "source": [
    "create_derived_avg_variables('^arpu_.*','arpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive based on total MOU (Minutes of Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.427118Z",
     "start_time": "2021-04-24T14:49:14.375Z"
    }
   },
   "outputs": [],
   "source": [
    "create_derived_avg_variables('^total.*mou_','total_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive based on volume of data usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.429354Z",
     "start_time": "2021-04-24T14:49:14.382Z"
    }
   },
   "outputs": [],
   "source": [
    "create_derived_avg_variables('^vol_.*','vol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:14:47.790957Z",
     "start_time": "2021-04-23T05:14:47.788267Z"
    }
   },
   "source": [
    "## Derive based on outgoing calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.431625Z",
     "start_time": "2021-04-24T14:49:14.389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handle the outgoing calls to customer care separately\n",
    "create_derived_avg_variables('^loc_og_t2c_mou_','loc_t2c_og')\n",
    "create_derived_avg_variables('^loc_og_.*','loc_og')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive based on incoming calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.433032Z",
     "start_time": "2021-04-24T14:49:14.397Z"
    }
   },
   "outputs": [],
   "source": [
    "create_derived_avg_variables('^loc_ic_.*','loc_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.434102Z",
     "start_time": "2021-04-24T14:49:14.402Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive for the roaming calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.435544Z",
     "start_time": "2021-04-24T14:49:14.409Z"
    }
   },
   "outputs": [],
   "source": [
    "create_derived_avg_variables('^roam_.*_mou_','roam_mou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dervice for recharge amount and drop the other rech columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.437084Z",
     "start_time": "2021-04-24T14:49:14.415Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['total_rech_data_amt_6'] = cust['total_rech_data_6']*cust['av_rech_amt_data_6']\n",
    "cust['total_rech_data_amt_7'] = cust['total_rech_data_7']*cust['av_rech_amt_data_7']\n",
    "cust['total_rech_data_amt_8'] = cust['total_rech_data_8']*cust['av_rech_amt_data_8']\n",
    "cust.drop(['total_rech_data_6','av_rech_amt_data_6','total_rech_data_7','av_rech_amt_data_7','total_rech_data_8','av_rech_amt_data_8'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.438511Z",
     "start_time": "2021-04-24T14:49:14.422Z"
    }
   },
   "outputs": [],
   "source": [
    "create_derived_avg_variables('^total_rech_.*amt_','total_rech_amt')\n",
    "create_derived_avg_variables('^count_rech_.*g_','count_rech')\n",
    "create_derived_avg_variables('^total_rech_num_','total_rech_num')\n",
    "create_derived_avg_variables('^max_rech_amt_','max_rech_amt')\n",
    "create_derived_avg_variables('^max_rech_data_','max_rech_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T12:56:35.780054Z",
     "start_time": "2021-04-24T12:56:35.718011Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.440098Z",
     "start_time": "2021-04-24T14:49:14.429Z"
    }
   },
   "outputs": [],
   "source": [
    "# TO ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.441676Z",
     "start_time": "2021-04-24T14:49:14.435Z"
    }
   },
   "outputs": [],
   "source": [
    "[col for col in cust.columns if re.search(f'rech', col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.443087Z",
     "start_time": "2021-04-24T14:49:14.441Z"
    }
   },
   "outputs": [],
   "source": [
    "cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to independent & dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.444253Z",
     "start_time": "2021-04-24T14:49:14.451Z"
    }
   },
   "outputs": [],
   "source": [
    "X = cust.drop([DEPENDENT_VARIABLE],axis=1)\n",
    "y = cust[DEPENDENT_VARIABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.445825Z",
     "start_time": "2021-04-24T14:49:14.456Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['is_hvc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.447097Z",
     "start_time": "2021-04-24T14:49:14.463Z"
    }
   },
   "outputs": [],
   "source": [
    "cust['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T03:22:44.881322Z",
     "start_time": "2021-04-21T03:22:10.485Z"
    }
   },
   "source": [
    "<font color='green'>\n",
    "    <b>Observations on class imbalance:</b><br>\n",
    "- In the given dataset, churn vs non-churn is at 10%-90%. <br>\n",
    "- This is a case of class imbalance where one class outnumbers the other. <br>\n",
    "- We can apply some of the class imbalance techniques to address this issue and observe how the models behave <br>\n",
    "- In this case study we shall use the oversampling & SMOTE techniques to address the class imbalance issue\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.448374Z",
     "start_time": "2021-04-24T14:49:14.471Z"
    }
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# fit predictor and target variablex_ros, \n",
    "X_oversampled, y_oversampled = over_sampler.fit_resample(X,y)\n",
    "\n",
    "\n",
    "print(f'''Shape of X before oversampling: {X.shape}\n",
    "Shape of X after oversampling: {X_oversampled.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "y_oversampled.value_counts(normalize=True) * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.449854Z",
     "start_time": "2021-04-24T14:49:14.478Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "\n",
    "print(f'''Shape of X before SMOTE: {X.shape}\n",
    "Shape of X after SMOTE: {X_smote.shape}''')\n",
    "\n",
    "print('\\nBalance of positive and negative classes (%):')\n",
    "y_smote.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split on original data (without oversampling or SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.451233Z",
     "start_time": "2021-04-24T14:49:14.494Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70% of data used as train data and the remaining 30% as test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split on oversampled data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.452446Z",
     "start_time": "2021-04-24T14:49:14.500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70% of data used as train data and the remaining 30% as test data\n",
    "X_oversampled_train, X_oversampled_test, y_oversampled_train, y_oversampled_test = train_test_split(X_oversampled,y_oversampled,test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split on SMOTE data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.453818Z",
     "start_time": "2021-04-24T14:49:14.506Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70% of data used as train data and the remaining 30% as test data\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote,y_smote,test_size = 0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.455327Z",
     "start_time": "2021-04-24T14:49:14.512Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_scale = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.457389Z",
     "start_time": "2021-04-24T14:49:14.517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the original dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test[cols_to_scale]  = scaler.transform(X_test[cols_to_scale] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.459218Z",
     "start_time": "2021-04-24T14:49:14.522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the oversampled dataset\n",
    "scaler_os = MinMaxScaler()\n",
    "X_oversampled_train[cols_to_scale] = scaler_os.fit_transform(X_oversampled_train[cols_to_scale])\n",
    "X_oversampled_test[cols_to_scale] = scaler_os.transform(X_oversampled_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.461045Z",
     "start_time": "2021-04-24T14:49:14.528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the SMOTE dataset\n",
    "scaler_smote = MinMaxScaler()\n",
    "X_smote_train[cols_to_scale] = scaler_smote.fit_transform(X_smote_train[cols_to_scale])\n",
    "X_smote_test[cols_to_scale] = scaler_smote.transform(X_smote_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.462703Z",
     "start_time": "2021-04-24T14:49:14.534Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set models to be run and compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.464320Z",
     "start_time": "2021-04-24T14:49:14.542Z"
    }
   },
   "outputs": [],
   "source": [
    "# All supported models that can be run\n",
    "ALL_SUPPORTED_MODELS = ['LOGISTRIC_REGRESSION','DECISION_TREE','RANDOM_FOREST','GAUSSIAN_NAIVE_BAYES','GRADIENT_BOOST','XGB_CLASSIFIER','SVM_CLASSIFIER','KNN_CLASSIFIER','ADABOOST_CLASSIFIER','MLP_CLASSIFIER']\n",
    "\n",
    "# Select models that needs to be run (Set to ALL_SUPPORTED_MODELS if all the models has to be run - RunTime could be high)\n",
    "MODELS_TO_RUN =     ['LOGISTRIC_REGRESSION','DECISION_TREE','RANDOM_FOREST','GAUSSIAN_NAIVE_BAYES','GRADIENT_BOOST','XGB_CLASSIFIER','ADABOOST_CLASSIFIER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.466134Z",
     "start_time": "2021-04-24T14:49:14.549Z"
    }
   },
   "outputs": [],
   "source": [
    "GRID_SEARCH_SCORING  = 'f1'# Metric used to identify the best model during hyperparameter tuning\n",
    "EVALUATION_METRIC = 'F1 Score' #'Accuracy','AUROC','Sensitivity','Specificity','Precision'\n",
    "SORT_ASCENDING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.467890Z",
     "start_time": "2021-04-24T14:49:14.556Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = list(set(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Random Forest - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.469047Z",
     "start_time": "2021-04-24T14:49:14.564Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [1, 2, 5, 10, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'max_features': [2,3,4],\n",
    "    'n_estimators': [10, 30, 50, 100, 200]\n",
    "}\n",
    "\n",
    "param_comb = 3\n",
    "\n",
    "# # Instantiate the grid search model - takes around 1hr 22m for PCA RF HPT\n",
    "# grid_search_rf = GridSearchCV(estimator=classifier_rf, param_grid=params, \n",
    "#                           cv=4, n_jobs=-1, verbose=1, scoring = GRID_SEARCH_SCORING)\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(estimator=classifier_rf, param_distributions=params, n_iter=param_comb, scoring=GRID_SEARCH_SCORING, n_jobs=-1, cv=4, verbose=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search for XGBoost - Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.470015Z",
     "start_time": "2021-04-24T14:49:14.571Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier_xgb = XGBClassifier(n_jobs = -1,objective = 'binary:logistic')\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        'n_estimators' : [100, 200, 500, 750], # no of trees \n",
    "        'learning_rate' : [0.01, 0.02, 0.05, 0.1, 0.25],  # eta\n",
    "        'min_child_weight': [1, 5, 7, 10],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 12]\n",
    "        }\n",
    "\n",
    "param_comb = 3 # to reduce run-time - testing (did not complete after 3 hours for 800)\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(classifier_xgb, param_distributions=params, n_iter=param_comb, scoring=GRID_SEARCH_SCORING, n_jobs=-1, cv=5, verbose=3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions - Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.470912Z",
     "start_time": "2021-04-24T14:49:14.580Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_fit_predict(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return get_performance_measures(Y_test = y_test, Y_predict = y_pred, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print elapsed time in min & secc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.472239Z",
     "start_time": "2021-04-24T14:49:14.587Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_elapsed_time(end_time,start_time):\n",
    "    total_time = end_time - start_time\n",
    "    print(f'Elapsed time: {total_time//60} min {round(total_time - total_time//60,3)} sec')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models based on MODELS_TO_RUN list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.475135Z",
     "start_time": "2021-04-24T14:49:14.594Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_all_models(X_train, X_test, y_train, y_test,model_type, model_result):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Logistic Regression\n",
    "    if 'LOGISTRIC_REGRESSION' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: Logistic Regression')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-LR'] = model_fit_predict(LogisticRegression(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    if 'DECISION_TREE' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: Decision Tree Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-DCART'] = model_fit_predict(DecisionTreeClassifier(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # Random Forest Classifier \n",
    "    if 'RANDOM_FOREST' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: Random Forest Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-RF'] = model_fit_predict(RandomForestClassifier(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # Naive Bayes Classifier\n",
    "    if 'GAUSSIAN_NAIVE_BAYES' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: Naive Bayes Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-NB'] = model_fit_predict(GaussianNB(),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # Gradient Boost Classifier\n",
    "    if 'GRADIENT_BOOST' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: Gradient Boost Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-GB'] = model_fit_predict(GradientBoostingClassifier(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # XGBoost Classifier\n",
    "    if 'XGB_CLASSIFIER' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: XGBoost Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-XGB'] = model_fit_predict(XGBClassifier(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    \n",
    "    # SVM Classifier\n",
    "    if 'SVM_CLASSIFIER' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: SVM Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-SVC'] = model_fit_predict(SVC(probability=True,random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # K-Nearest Neighbors Classifier\n",
    "    if 'KNN_CLASSIFIER' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: K-Nearest Neighbors Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-KNN'] = model_fit_predict(KNeighborsClassifier(),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "\n",
    "    # AdaBoost Classifier\n",
    "    if 'ADABOOST_CLASSIFIER' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: AdaBoost Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-ABC'] = model_fit_predict(AdaBoostClassifier(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    # MLP Classifier\n",
    "    if 'MLP_CLASSIFIER' in MODELS_TO_RUN:\n",
    "        print(f'\\nRunning Model: MLP Classifier')\n",
    "        model_start_time = time.time()\n",
    "        model_result[f'{model_type}-MLP'] = model_fit_predict(MLPClassifier(random_state=42),X_train, X_test, y_train, y_test)\n",
    "        print_elapsed_time(time.time(),model_start_time)\n",
    "    \n",
    "    print('\\nCOMPLETED RUNNING ALL THE MODELS SUCCESSFULLY!!')\n",
    "    print_elapsed_time(time.time(),start_time)\n",
    "    \n",
    "    return model_result.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.476444Z",
     "start_time": "2021-04-24T14:49:14.600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute classification accuracy: percentage of correct predictions\n",
    "def get_accuracy(Y_test, Y_predict):\n",
    "    accuracy_score_value = accuracy_score(Y_test, Y_predict)\n",
    "    return accuracy_score_value\n",
    "        \n",
    "# Compute the confusion metrics\n",
    "def get_confusion_matrix(Y_test, Y_predict, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    conf_matrix = pd.DataFrame(confusion_matrix(Y_test, Y_predict, labels=labels), columns=labels, index=labels)\n",
    "    conf_matrix_df = conf_matrix.add_prefix('Predicted ')\n",
    "    conf_matrix_df.index = ['Actual ' + str(row_name) for row_name in conf_matrix_df.index]\n",
    "    return conf_matrix_df, conf_matrix\n",
    "\n",
    "# Compute null accuracy\n",
    "def get_null_accuracy(Y_test, multiclass):\n",
    "    # Null accuracy: accuracy that could be achieved by always predicting the most frequent class\n",
    "    # Used as a reference as minimum accuracy to be achieved with the model\n",
    "    null_accuracy = Y_test.value_counts().head(1) / len(Y_test)\n",
    "    return null_accuracy.values[0]\n",
    "\n",
    "\n",
    "def get_individual_values_from_confusion_matrix(conf_matrix):\n",
    "    # https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "    import numpy as np\n",
    "    FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n",
    "    FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n",
    "    TP = np.diag(conf_matrix)\n",
    "    TN = conf_matrix.values.sum() - (FP + FN + TP)\n",
    "\n",
    "    return FP, FN, TP, TN\n",
    "\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "def get_sensitivity(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "\n",
    "# Specificity or true negative rate\n",
    "def get_specificity(TN, FP):\n",
    "    return TN / (TN + FP)\n",
    "\n",
    "\n",
    "# Precision or positive predictive value\n",
    "def get_precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "\n",
    "# F1-SCORE\n",
    "def get_f1_score(precision, sensitivity):\n",
    "    return 2 * ((precision * sensitivity) / (precision + sensitivity))\n",
    "\n",
    "\n",
    "# Negative predictive value\n",
    "def get_negative_predictive_value(TN, FN):\n",
    "    return TN / (TN + FN)\n",
    "\n",
    "\n",
    "# Fall out or false positive rate\n",
    "def get_false_positive_rate(FP, TN):\n",
    "    return FP / (FP + TN)\n",
    "\n",
    "\n",
    "# False negative rate\n",
    "def get_false_negative_rate(FN, TP):\n",
    "    return FN / (TP + FN)\n",
    "\n",
    "\n",
    "# False discovery rate\n",
    "def get_false_discovery_rate(FP, TP):\n",
    "    return FP / (TP + FP)\n",
    "\n",
    "\n",
    "# Log loss\n",
    "def get_log_loss(y_true, y_pred_proba):\n",
    "    from sklearn.metrics import log_loss\n",
    "    return log_loss(y_true, y_pred_proba, eps=1e-15)\n",
    "\n",
    "# AUROC score\n",
    "def get_roc_auc_score(Y_test,Y_predict):\n",
    "    return roc_auc_score(Y_test,Y_predict)\n",
    "\n",
    "def get_performance_measures(Y_test, Y_predict, labels):\n",
    "    conf_matrix_df, conf_matrix = get_confusion_matrix(Y_test, Y_predict, labels)\n",
    "    FP, FN, TP, TN = get_individual_values_from_confusion_matrix(conf_matrix)\n",
    "    df = pd.DataFrame({\n",
    "        'Accuracy': get_accuracy(Y_test,Y_predict),\n",
    "        'Null Accuracy': get_null_accuracy(Y_test,Y_predict),\n",
    "        'AUROC':get_roc_auc_score(Y_test,Y_predict),\n",
    "        'Sensitivity': get_sensitivity(TP, FN),\n",
    "        'Specificity': get_specificity(TN, FP),\n",
    "        'Precision': get_precision(TP, FP),\n",
    "        'F1 Score': get_f1_score(get_precision(TP, FP), get_sensitivity(TP, FN)),\n",
    "        'Negative Predictive Value': get_negative_predictive_value(TN, FN),\n",
    "        'False Positive Rate': get_false_positive_rate(FP, TN),\n",
    "        'False Negative Rate': get_false_negative_rate(FN, TP),\n",
    "        'False Discovery Rate': get_false_discovery_rate(FP, TP),\n",
    "    })#.T.add_prefix('Class ')\n",
    "    # Creates metrics for each label. Return details of only class 1 (customer churn)\n",
    "    return (df.loc[1]*100).round(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building 1 - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.477680Z",
     "start_time": "2021-04-24T14:49:14.609Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.478791Z",
     "start_time": "2021-04-24T14:49:14.615Z"
    }
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.479910Z",
     "start_time": "2021-04-24T14:49:14.621Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.bar(range(1,len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)\n",
    "plt.bar(range(1,31), pca.explained_variance_ratio_[1:31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.481022Z",
     "start_time": "2021-04-24T14:49:14.627Z"
    }
   },
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Making the scree plot\n",
    "plt.plot(range(1,len(var_cumu)+1), var_cumu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.482134Z",
     "start_time": "2021-04-24T14:49:14.633Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(var_cumu).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "<b>PCA Inference:</b> <br>\n",
    "- 94% of the variance is explained by the first 20 Principal Components <br>\n",
    "- We can try running models with 20 components and check how they perform\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PCA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.483851Z",
     "start_time": "2021-04-24T14:49:14.642Z"
    }
   },
   "outputs": [],
   "source": [
    "num_pcs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.484918Z",
     "start_time": "2021-04-24T14:49:14.647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the top 20 principal components \n",
    "pcs = IncrementalPCA(n_components=num_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.485940Z",
     "start_time": "2021-04-24T14:49:14.653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility method to create the new principal component datasets on the train & test data\n",
    "def create_pca_data(train,test):\n",
    "    train_pca = pd.DataFrame(pcs.fit_transform(train)).add_prefix('PC')\n",
    "    # Index is lost after PCA as it works on Numpy arrays. \n",
    "    # Ref: https://github.com/scikit-learn/scikit-learn/issues/8238\n",
    "    train_pca.index = train.index\n",
    "    print(f'Train PCA data shape:{train_pca.shape}')\n",
    "    display(train_pca.head(3))\n",
    "\n",
    "    test_pca = pd.DataFrame(pcs.transform(test)).add_prefix('PC')\n",
    "    test_pca.index = test.index\n",
    "    print(f'Test PCA data shape:{test_pca.shape}')\n",
    "    display(test_pca.head(3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train_pca, test_pca\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.486945Z",
     "start_time": "2021-04-24T14:49:14.661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create PCA dataset for the original dataset\n",
    "X_train_pca, X_test_pca = create_pca_data(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.488073Z",
     "start_time": "2021-04-24T14:49:14.669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create PCA dataset for the oversampled dataset\n",
    "X_oversampled_train_pca, X_oversampled_test_pca = create_pca_data(X_oversampled_train,X_oversampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.489093Z",
     "start_time": "2021-04-24T14:49:14.678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create PCA dataset for the SMOTE dataset\n",
    "X_smote_train_pca, X_smote_test_pca = create_pca_data(X_smote_train,X_smote_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for multicollinearity - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the features (Principal Components) created from PCA are not correlated to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.490103Z",
     "start_time": "2021-04-24T14:49:14.686Z"
    }
   },
   "outputs": [],
   "source": [
    "corrmat = np.corrcoef(X_train_pca.transpose())\n",
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.491149Z",
     "start_time": "2021-04-24T14:49:14.693Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,15])\n",
    "sns.heatmap(corrmat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.492160Z",
     "start_time": "2021-04-24T14:49:14.698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the data of PC0 vs PC1\n",
    "df_final = pd.concat([X_train_pca, y_train], axis=1)\n",
    "sns.scatterplot(data=df_final, x=\"PC0\", y=\"PC1\",hue=\"churn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.493193Z",
     "start_time": "2021-04-24T14:49:14.705Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.494366Z",
     "start_time": "2021-04-24T14:49:14.713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default model run\n",
    "run_all_models(X_train_pca, X_test_pca, y_train, y_test,'PCA',model_result_pca)\n",
    "model_result_pca\n",
    "#model_result_pca.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.495420Z",
     "start_time": "2021-04-24T14:49:14.720Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building with HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.496567Z",
     "start_time": "2021-04-24T14:49:14.727Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type_pca_hpt = 'PCA-HPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPT for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.497599Z",
     "start_time": "2021-04-24T14:49:14.735Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search_rf.fit(X_train_pca,y_train)\n",
    "rf_best_est = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.498752Z",
     "start_time": "2021-04-24T14:49:14.741Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca[f'{model_type_pca_hpt}-RF'] = model_fit_predict(rf_best_est,X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPT for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.499648Z",
     "start_time": "2021-04-24T14:49:14.748Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "random_search_xgb.fit(X_train_pca,y_train)\n",
    "xgb_best_est = random_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.500760Z",
     "start_time": "2021-04-24T14:49:14.753Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca[f'{model_type_pca_hpt}-XGB'] = model_fit_predict(xgb_best_est,X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.501942Z",
     "start_time": "2021-04-24T14:49:14.761Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all_models(X_oversampled_train_pca, X_oversampled_test_pca, y_oversampled_train, y_oversampled_test,'PCA - Oversampled',model_result_pca)\n",
    "model_result_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.503003Z",
     "start_time": "2021-04-24T14:49:14.770Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all_models(X_smote_train_pca, X_smote_test_pca, y_smote_train, y_smote_test,'PCA - SMOTE',model_result_pca)\n",
    "model_result_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on (SMOTE + HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.504219Z",
     "start_time": "2021-04-24T14:49:14.777Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type_pca_smotehpt = 'PCA-SMOTE+HPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE+HPT for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.505200Z",
     "start_time": "2021-04-24T14:49:14.783Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# grid_search_rf.fit(X_smote_train_pca,y_smote_train)\n",
    "# rf_smote_best_est = grid_search_rf.best_estimator_\n",
    "\n",
    "random_search_rf.fit(X_smote_train_pca,y_smote_train)\n",
    "rf_smote_best_est = random_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.506337Z",
     "start_time": "2021-04-24T14:49:14.789Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca[f'{model_type_pca_smotehpt}-RF'] = model_fit_predict(rf_smote_best_est,X_smote_train_pca, X_smote_test_pca, y_smote_train, y_smote_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  SMOTE+HPT for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.507288Z",
     "start_time": "2021-04-24T14:49:14.799Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.508332Z",
     "start_time": "2021-04-24T14:49:14.805Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "random_search_xgb.fit(X_smote_train_pca,y_smote_train)\n",
    "xgb_smote_best_est = random_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.509242Z",
     "start_time": "2021-04-24T14:49:14.810Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca[f'{model_type_pca_smotehpt}-XGB'] = model_fit_predict(xgb_smote_best_est,X_smote_train_pca, X_smote_test_pca, y_smote_train, y_smote_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary from all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.510373Z",
     "start_time": "2021-04-24T14:49:14.817Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_pca.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building 2 - without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build  Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.511462Z",
     "start_time": "2021-04-24T14:49:14.826Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_featimp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.512499Z",
     "start_time": "2021-04-24T14:49:14.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default model run - Feature Importance (FI)\n",
    "run_all_models(X_train, X_test, y_train, y_test,'FI', model_result_featimp)\n",
    "\n",
    "model_result_featimp.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.513489Z",
     "start_time": "2021-04-24T14:49:14.840Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type_FI_hpt = 'FI-HPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPT for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.514431Z",
     "start_time": "2021-04-24T14:49:14.847Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid_search_rf.fit(X_train,y_train)\n",
    "#rf_fi_best_est = grid_search_rf.best_estimator_\n",
    "random_search_rf.fit(X_train,y_train)\n",
    "rf_fi_best_est = random_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.515547Z",
     "start_time": "2021-04-24T14:49:14.852Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_featimp[f'{model_type_FI_hpt}-RF'] = model_fit_predict(rf_fi_best_est,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPT for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.516516Z",
     "start_time": "2021-04-24T14:49:14.859Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "random_search_xgb.fit(X_train,y_train)\n",
    "xgb_fi_best_est = random_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.517715Z",
     "start_time": "2021-04-24T14:49:14.864Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_featimp[f'{model_type_FI_hpt}-XGB'] = model_fit_predict(xgb_fi_best_est,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.518714Z",
     "start_time": "2021-04-24T14:49:14.878Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all_models(X_oversampled_train, X_oversampled_test, y_oversampled_train, y_oversampled_test,'FI - Oversampled', model_result_featimp)\n",
    "\n",
    "model_result_featimp.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with SMOTE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.519685Z",
     "start_time": "2021-04-24T14:49:14.886Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all_models(X_smote_train, X_smote_test, y_smote_train, y_smote_test,'FI - SMOTE', model_result_featimp)\n",
    "\n",
    "model_result_featimp.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with SMOTE+HPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.520677Z",
     "start_time": "2021-04-24T14:49:14.892Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type_FI_smotehpt = 'FI-SMOTE+HPT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPT for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.521799Z",
     "start_time": "2021-04-24T14:49:14.898Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# grid_search_rf.fit(X_smote_train_pca,y_smote_train)\n",
    "# rf_fi_smote_best_est = grid_search_rf.best_estimator_\n",
    "\n",
    "random_search_rf.fit(X_smote_train,y_smote_train)\n",
    "rf_fi_smote_best_est = random_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.522695Z",
     "start_time": "2021-04-24T14:49:14.903Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_featimp[f'{model_type_FI_smotehpt}-RF'] = model_fit_predict(rf_fi_smote_best_est,X_smote_train, X_smote_test, y_smote_train, y_smote_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPT for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.523663Z",
     "start_time": "2021-04-24T14:49:14.910Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "random_search_xgb.fit(X_smote_train,y_smote_train)\n",
    "xgb_fi_smote_best_est = random_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.524681Z",
     "start_time": "2021-04-24T14:49:14.915Z"
    }
   },
   "outputs": [],
   "source": [
    "model_result_featimp[f'{model_type_FI_smotehpt}-XGB'] = model_fit_predict(xgb_fi_smote_best_est,X_smote_train, X_smote_test, y_smote_train, y_smote_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary from all the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.525641Z",
     "start_time": "2021-04-24T14:49:14.924Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_result_featimp.T.sort_values(by=EVALUATION_METRIC,ascending=SORT_ASCENDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance with Random Forest & XGB models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.526660Z",
     "start_time": "2021-04-24T14:49:14.933Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'Important features from Random Forest HPT model')\n",
    "\n",
    "imp_rf_df = pd.DataFrame({\n",
    "    \"Varname\": X_train.columns,\n",
    "    \"Imp\": rf_fi_best_est.feature_importances_\n",
    "})\n",
    "imp_rf_df.sort_values(by=\"Imp\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.527783Z",
     "start_time": "2021-04-24T14:49:14.939Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Important features from XGB HPT model')\n",
    "\n",
    "imp_xgb_df = pd.DataFrame({\n",
    "    \"Varname\": X_train.columns,\n",
    "    \"Imp\": xgb_fi_best_est.feature_importances_\n",
    "})\n",
    "imp_xgb_df.sort_values(by=\"Imp\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T14:50:45.528906Z",
     "start_time": "2021-04-24T14:49:14.946Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'Important features from RF - oversampled model')\n",
    "model_rf_oversampled = RandomForestClassifier(random_state=42).fit(X_oversampled_train, y_oversampled_train)\n",
    "\n",
    "imp_rf_oversampled_df = pd.DataFrame({\n",
    "    \"Varname\": X_oversampled_train.columns,\n",
    "    \"Imp\": model_rf_oversampled.feature_importances_\n",
    "})\n",
    "imp_rf_oversampled_df.sort_values(by=\"Imp\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model - with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, choose a model based on some evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-24T09:52:21.781996Z",
     "start_time": "2021-04-24T09:52:21.777299Z"
    }
   },
   "source": [
    "<font color='green'>\n",
    "<b>INSIGHTS:</b> <br>\n",
    "- Models were created with 3 different types of data: <br>\n",
    "-- Input Data<br>\n",
    "-- Oversampled Data<br>\n",
    "-- SMOTE Data<br>\n",
    "- Based on the F1-Score and AUROC, we can notice that the models created with the oversampled data before the best.\n",
    "- \n",
    "- The models with oversampled data perform better than the <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying important predictors, display them visually - you can use plots, summary tables etc. - whatever you think best conveys the importance of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion - recommendation to manage customer churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, recommend strategies to manage customer churn based on your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T07:11:55.680525Z",
     "start_time": "2021-04-22T07:11:55.667328Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "My Steps",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
